---
title: "Exercise 5"
author: "Tobias Raidl, 11717659"
date: "2023-11-28"
output: pdf_document
header-includes:
  \usepackage{fvextra}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy=TRUE)
```

```{r}
library(ROCit)
library(dplyr)
library(MASS)
library(mltools)
library(data.table)
df = one_hot(as.data.table(Loan), c("Home", "EmpLen"))
df = dplyr::select(df, -Term)


set.seed(6669)
sample = sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7,0.3))
train = df[sample, ]
test = df[!sample, ]
X_train = dplyr::select(train, -Status)
X_test = dplyr::select(test, -Status)
y_train = train$Status
y_test = test$Status

get_misclassification_rate = function(tp, fp, tn, fn) {
  tpr = tp/(tp+fn)
  tnr = tn/(tn+fp)
  eval = list(misclass_rate=(fp+fn)/(fp+tn+fn+tp), balanced_accuracy=(tpr+tnr)/2)
  return(eval)
}
```

Remove collinearity
```{r}
library(corrplot)
num_train = train
num_train$Status = as.integer(factor(num_train$Status))
corrplot(cor(num_train))
library(caret)
indices_to_drop <- findCorrelation(cor(num_train), cutoff = 0.3)
corrplot(cor(dplyr::select(num_train, -indices_to_drop)))

train = dplyr::select(num_train, -indices_to_drop)
X_train = dplyr::select(num_train, -indices_to_drop)
```

# 1
## a
```{r}
lda = lda(Status~., X_train)
summary(lda)
y_pred = predict(lda, X_train)$class
conf_mat = table(y_train, y_pred)
tp = conf_mat[1,1]
tn = conf_mat[2,2]
fp = conf_mat[1,2]
fn = conf_mat[2,1]
get_misclassification_rate(tp,fp,tn,fn)
```